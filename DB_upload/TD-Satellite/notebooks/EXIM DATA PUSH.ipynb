{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57485fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathos.pools import ThreadPool, ProcessPool\n",
    "from functools import partial\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from src.funcs.db_io import (create_db_connection, read_table_to_df)\n",
    "from configs import db_config, path_config\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from heapq import nsmallest\n",
    "from src.funcs.data_io import (get_all_file_paths_in_dir, process_site_table)\n",
    "from src.funcs.db_io import append_data_to_table, tensor_aws_db1_url\n",
    "from src.funcs.decorators import timer\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef021f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = create_db_connection(dbname=db_config.dbname,\n",
    "                                     host=db_config.host,\n",
    "                                     port=db_config.port,\n",
    "                                     user=db_config.user,\n",
    "                                     password=db_config.password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7820f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = read_table_to_df(con=db_connection,\n",
    "                                table_str=db_config.site_table,\n",
    "                                schema=db_config.site_table_schema)\n",
    "\n",
    "locations_dict = process_site_table(site_df=locations_df, site_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc50557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file_paths = get_all_file_paths_in_dir(folder_path=path_config.exim_data_path,\n",
    "                                          find_match='EXIM-CT',\n",
    "                                          ignore_matches=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511b2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file_paths = sorted(nc_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5a1d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = nc_file_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8203500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class to extract data from a NETCDF file\n",
    "\"\"\"\n",
    "import re\n",
    "from heapq import nsmallest\n",
    "from ntpath import basename\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import haversine\n",
    "\n",
    "\n",
    "class EXIMNCExtractor:\n",
    "\n",
    "    def __init__(self,\n",
    "                 nc_file_path,\n",
    "                 locations_dict=None,\n",
    "                 lat_col=None,\n",
    "                 lon_col=None,\n",
    "                 exclude_cols_str_matching=None,\n",
    "                 extract_attrs=None):\n",
    "        \"\"\"\n",
    "        Extracts dataframe from NETCDF File with given params\n",
    "\n",
    "        :param nc_file_path: File path to read\n",
    "        :type nc_file_path: str, path like\n",
    "\n",
    "        :param locations_dict: locations dictionary to filter netcdf file variables. Optional, default to None.\n",
    "            Will return all lat lon info if None.\n",
    "        :type locations_dict: dict\n",
    "\n",
    "        :param lat_col: Latitude index label in netcdf file. Optional, defaults to None - will try to infer\n",
    "        :type lat_col: str\n",
    "\n",
    "        :param lon_col: Longitude index label in netcdf file. Optional, defaults to None - will try to infer\n",
    "        :type lon_col: str\n",
    "\n",
    "        :param exclude_cols_str_matching: List of string matches to avoid in output. Can be part of the column names.\n",
    "            Optional, defaults to ['bnds']. i.e. all column labels with 'bnds' will be omitted.\n",
    "        :type exclude_cols_str_matching: [str], list of str\n",
    "\n",
    "        :param extract_attrs: List of attribute names of the netcdf file to extract.\n",
    "            Defaults to ['title', 'experiment', 'creation_date']\n",
    "        :type lat_col: [str], list of str\n",
    "        \"\"\"\n",
    "        self.file_path = nc_file_path\n",
    "        self.locs_dict = locations_dict\n",
    "        self.lat_col = lat_col\n",
    "        self.lon_col = lon_col\n",
    "        self.exclude_cols_str_matching = exclude_cols_str_matching or ['bnds']\n",
    "        self.global_attrs = extract_attrs or ['keywords',\n",
    "                                              'date_created',\n",
    "                                              'time_coverage_start',\n",
    "                                              'time_coverage_end',\n",
    "                                              'product_name',\n",
    "                                              'nominal_product_time',\n",
    "                                              'satellite_identifier',\n",
    "                                              'id',\n",
    "                                              'summary',\n",
    "                                              'title']\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_haversine_dist(loc1, loc2, unit='KM') -> float:\n",
    "        \"\"\"\n",
    "        Calculates haversine (great-circle) distance between two co-ordinates in km\n",
    "        :param loc1: location 1 (lat1, lon1)\n",
    "        :param loc2: location 2 (lat2, lon2)\n",
    "        :param unit: UNITS of distance, optional, defaults to KM. Options = [KM, MI] i.e. [kilometers, miles]\n",
    "        :return: distance in unit\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        if not isinstance(loc1, tuple) or not isinstance(loc2, tuple):\n",
    "            raise TypeError(\"Cannot calculate distance. Please provide location as (lat, lon) \")\n",
    "\n",
    "        if 'km' in unit.lower():\n",
    "            unit = haversine.Unit.KILOMETERS\n",
    "        elif 'mi' in unit.lower():\n",
    "            unit = haversine.Unit.MILES\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only 'km' or 'mi' are implemented units while calculating haversine distance.\")\n",
    "        return haversine.haversine(point1=loc1, point2=loc2, unit=unit)\n",
    "\n",
    "    @staticmethod\n",
    "    def haversine_np(lon1, lat1, lon2, lat2):\n",
    "        \"\"\"\n",
    "        Calculate the great circle distance between two points\n",
    "        on the earth (specified in decimal degrees)\n",
    "\n",
    "        All args must be of equal length.\n",
    "\n",
    "        \"\"\"\n",
    "        lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "\n",
    "        a = np.sin(dlat / 2.0) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0) ** 2\n",
    "\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        return 6367 * c\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_columns_matching(data_frame, col_matches) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Drops columns from the dataframe that matches any given str in the iter of col_matches\n",
    "        \"\"\"\n",
    "        temp_df = data_frame.copy()\n",
    "        drop_cols = [col for col in data_frame.columns if any(x.lower() in col.lower() for x in col_matches)]\n",
    "        return temp_df.drop(drop_cols, axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_attrs_from_xarray(xarray_obj, attr_names) -> dict:\n",
    "        \"\"\"Extract attributes from NC file with the given attr_names\"\"\"\n",
    "        return {name: xarray_obj.attrs.get(name) for name in attr_names}\n",
    "\n",
    "    @staticmethod\n",
    "    def add_dict_items_to_df(data_frame, attr_dict, prefix=None):\n",
    "        temp_df = data_frame.copy()\n",
    "        for counter, (attr, value) in enumerate(attr_dict.items()):\n",
    "            name = f\"{prefix}_{attr}\" if prefix else attr\n",
    "            temp_df.insert(loc=counter, column=name, value=value)\n",
    "        return temp_df\n",
    "\n",
    "    @staticmethod\n",
    "    def get_timezone(xarray_obj):\n",
    "        return str(pd.to_datetime(xarray_obj.attrs.get('date_created', None)).tz)\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_special_chars(my_string, replace_with='_') -> str:\n",
    "        \"\"\"\n",
    "        Replaces special characs from a string with regex.\n",
    "        \"\"\"\n",
    "        return re.sub('[^A-Za-z0-9]+', replace_with, my_string).lower()\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_all_vars(xr_obj):\n",
    "        output_df = pd.DataFrame()\n",
    "        var_names = list(xr_obj.variables.keys())\n",
    "        for var in var_names:\n",
    "            var_obj = xr_obj.variables.get(var)\n",
    "            if var_obj is not None:\n",
    "                melted_var = pd.DataFrame({var: var_obj.values.ravel()})\n",
    "                output_df = pd.concat([output_df, melted_var], axis=1)\n",
    "        return output_df\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_cords(xr_obj, lat_col, lon_col):\n",
    "        melted_lats = pd.DataFrame({lat_col: xr_obj.coords[lat_col].values.ravel()})\n",
    "        melted_lons = pd.DataFrame({lon_col: xr_obj.coords[lon_col].values.ravel()})\n",
    "        return pd.concat([melted_lats, melted_lons], axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def find_k_closest_number(find_number, search_array, k):\n",
    "        return nsmallest(k, search_array, key=lambda x: abs(x - find_number))\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_minutes_to_timestamp(ts, mins):\n",
    "        return ts + pd.Timedelta(minutes=mins)\n",
    "\n",
    "    def add_calculated_time_index(self, data_frame, time_col):\n",
    "        temp_df = data_frame.copy()\n",
    "        temp_df['time_split'] = temp_df[time_col].apply(lambda x: x.split('Z'))\n",
    "\n",
    "        # EXTRACT HORIZON TIME\n",
    "        try:\n",
    "            temp_df['horizon_time'] = temp_df['time_split'].apply(lambda x: self.replace_special_chars(my_string=x[1], \n",
    "                                                                                                         replace_with=''))\n",
    "        except IndexError:\n",
    "            temp_df['horizon_time'] = '0'\n",
    "\n",
    "        try:\n",
    "            temp_df['horizon_time'] = temp_df['horizon_time'].apply(lambda x: int(x))\n",
    "        except ValueError:\n",
    "            temp_df['horizon_time'] = 0\n",
    "        \n",
    "        # EXTRACT BASETIME\n",
    "        temp_df['base_time'] = temp_df['time_split'].apply(lambda x: x[0])\n",
    "        temp_df['base_time'] = pd.to_datetime(temp_df['base_time']).dt.round('15min')\n",
    "        temp_df[f\"calc_{time_col}\"] = temp_df.apply(lambda row: self.add_minutes_to_timestamp(ts=row['base_time'], \n",
    "                                                                                          mins=row['horizon_time']), \n",
    "                                                axis=1)\n",
    "\n",
    "        temp_df.drop(['horizon_time', 'base_time', 'time_split'], axis=1, inplace=True)\n",
    "        return temp_df\n",
    "\n",
    "    def open_xarray_obj(self):\n",
    "        \"\"\"Opens xarray dataframe from netcdf file\"\"\"\n",
    "        return xr.open_dataset(self.file_path)\n",
    "\n",
    "    def add_timezone(self, data_frame, xarray_obj):\n",
    "        temp_df = data_frame.copy()\n",
    "        temp_df['tz'] = self.get_timezone(xarray_obj=xarray_obj)\n",
    "        return temp_df\n",
    "\n",
    "    def clean_col_names(self, data_frame) -> pd.DataFrame:\n",
    "        \"\"\"Clean column names from special characters\"\"\"\n",
    "        temp_df = data_frame.copy()\n",
    "        temp_df.columns = [self.replace_special_chars(col) for col in temp_df.columns]\n",
    "        return temp_df\n",
    "\n",
    "    def find_closest_distance_haversine_np(self, locations_dict, lat_lon_df, lat_col='lat', lon_col='lon'):\n",
    "        output_dict = {}\n",
    "        for location in locations_dict:\n",
    "            site_actual_location = locations_dict.get(location)\n",
    "            site_lat = site_actual_location[0]\n",
    "            site_lon = site_actual_location[1]\n",
    "\n",
    "            temp_df = lat_lon_df.copy()\n",
    "            temp_df['site_lat'] = site_lat\n",
    "            temp_df['site_lon'] = site_lon\n",
    "            temp_df['distance'] = self.haversine_np(lon1=temp_df[lon_col],\n",
    "                                                    lat1=temp_df[lat_col],\n",
    "                                                    lon2=temp_df['site_lon'],\n",
    "                                                    lat2=temp_df['site_lat'])\n",
    "            required_row = temp_df.loc[temp_df['distance'].idxmin()]\n",
    "            required_lat = required_row.loc[lat_col]\n",
    "            required_lon = required_row.loc[lon_col]\n",
    "            output_row = {location: {'NC': (required_lat, required_lon), 'SITE': site_actual_location}}\n",
    "            output_dict.update(output_row)\n",
    "        return output_dict\n",
    "\n",
    "    def get_closest_nc_distances(self, locations_dict, xarray_df, lat_col, lon_col) -> dict:\n",
    "        \"\"\"\n",
    "        Prepares a dictionary of actual site lat lons and the closes lat lons in a dataframe\n",
    "        :param locations_dict: Locations dict in format {site : (lat, lon), site2: (lat2, lon2). .. .}\n",
    "        :param xarray_df: dataframe containing lat lon cols to search from\n",
    "        :param lat_col: column label containing lats\n",
    "        :param lon_col: column label containing lons\n",
    "        :return: dictionary of actual site lat lons and the closes lat lons found\n",
    "            {'site: {'SITE': (lat, lon), 'NC':(lat`, lon`)}, 'site2':{'SITE': (lat, lon), 'NC':(lat`, lon`)} ... }\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        lat_lon_df = xarray_df[[lat_col, lon_col]].drop_duplicates().reset_index(drop=True).copy()\n",
    "        return self.find_closest_distance_haversine_np(locations_dict=locations_dict,\n",
    "                                                       lat_lon_df=lat_lon_df,\n",
    "                                                       lat_col=lat_col,\n",
    "                                                       lon_col=lon_col)\n",
    "\n",
    "    def filter_xarray_df_for_locs(self, xarray_df, location_dict, lat_col, lon_col) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filter xarray dataframe for incoming locations\n",
    "        :param xarray_df: xarray df\n",
    "        :param location_dict: Locations dict in format {site : (lat, lon), site2: (lat2, lon2). .. .}\n",
    "        :param lat_col: col label containing latitude\n",
    "        :param lon_col: col label containing longitude\n",
    "        :return: netcdf dataframe filtered for locations\n",
    "        \"\"\"\n",
    "        # GET AVAIL LOCATIONS\n",
    "        locations_dict_nc = self.get_closest_nc_distances(locations_dict=location_dict,\n",
    "                                                          xarray_df=xarray_df,\n",
    "                                                          lat_col=lat_col,\n",
    "                                                          lon_col=lon_col)\n",
    "        # ITER OVER SITES\n",
    "        file_df = pd.DataFrame()\n",
    "        for location_name, location_meta in locations_dict_nc.items():\n",
    "            actual_site_loc = location_meta['SITE']\n",
    "            nc_site_loc = location_meta['NC']\n",
    "\n",
    "            loc_df = xarray_df[(xarray_df[lat_col] == nc_site_loc[0]) &\n",
    "                               (xarray_df[lon_col] == nc_site_loc[1])].copy().reset_index(drop=True)\n",
    "            loc_df['site_name'] = location_name\n",
    "            loc_df['site_lat'] = actual_site_loc[0]\n",
    "            loc_df['site_lon'] = actual_site_loc[0]\n",
    "            loc_df['distance_site_grid_point_km'] = self.calc_haversine_dist(loc1=actual_site_loc,\n",
    "                                                                             loc2=nc_site_loc,\n",
    "                                                                             unit='KM')\n",
    "            file_df = pd.concat([file_df, loc_df], axis=0)\n",
    "        return file_df.reset_index(drop=True)\n",
    "\n",
    "    def get_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        wrapper for:\n",
    "        1. Conversion process from NETCDF TO XARRAY\n",
    "        2. Extracting attributes & dataframe\n",
    "        3. Filtering for locations\n",
    "        4. Cleaning of column names and dropping extra columns\n",
    "        \"\"\"\n",
    "        xarray_obj = self.open_xarray_obj()  # OPEN X ARRAY OBJECT\n",
    "        xarray_attrs = self.get_attrs_from_xarray(xarray_obj=xarray_obj,\n",
    "                                                  attr_names=self.global_attrs)  # EXTRACT ATTRIBUTES\n",
    "\n",
    "        xarray_df = self.extract_all_vars(xr_obj=xarray_obj)\n",
    "        if self.locs_dict:\n",
    "            xarray_df = self.filter_xarray_df_for_locs(xarray_df=xarray_df,\n",
    "                                                       location_dict=self.locs_dict,\n",
    "                                                       lat_col=self.lat_col,\n",
    "                                                       lon_col=self.lon_col)\n",
    "\n",
    "        xarray_df = (xarray_df\n",
    "                     .pipe(self.drop_columns_matching, self.exclude_cols_str_matching)  # EXCLUDE COLS (Optional)\n",
    "                     .pipe(self.add_timezone, xarray_obj)  # ADD TIME ZONE IF PRESENT  (FROM 'date_created' attr)\n",
    "                     .pipe(self.add_dict_items_to_df, xarray_attrs)  # ADD ATTRIBUTES FROM NETCDF ATTRIBUTES\n",
    "                     .pipe(self.add_calculated_time_index, 'nominal_product_time')  # CONVERT COL TO DATETIME LIKE\n",
    "                     .pipe(self.add_calculated_time_index, 'date_created')  # CONVERT COL TO DATETIME LIKE\n",
    "                     .pipe(self.clean_col_names)# REMOVE SPECIAL CHARS FROM COL NAMES\n",
    "                     )\n",
    "        xarray_df['file_name'] = basename(self.file_path)\n",
    "        return xarray_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce0c2406",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xarray_df = EXIMNCExtractor(nc_file_path=nc_file_paths[2], \n",
    "                               locations_dict=locations_dict, \n",
    "                               lat_col='lat',\n",
    "                               lon_col='lon', \n",
    "                               exclude_cols_str_matching=['nx', 'ny']).get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40c84369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xarray_df['row_id'] = range(1, xarray_df.shape[0] + 1)\n",
    "xarray_df['log_ts'] = datetime.datetime.now()\n",
    "xarray_df.to_sql(name='nwc_exim_ct', \n",
    "                 schema=db_config.satellite_schema,\n",
    "                 con=db_connection,\n",
    "                 index=False,\n",
    "                 if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40717256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd92f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd03673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
