{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0dfe137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathos.pools import ThreadPool, ProcessPool\n",
    "from functools import partial\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from src.funcs.db_io import (create_db_connection, read_table_to_df)\n",
    "from configs import db_config\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from heapq import nsmallest\n",
    "from src.funcs.data_io import (get_all_file_paths_in_dir, process_site_table)\n",
    "from src.funcs.db_io import append_data_to_table, tensor_aws_db1_url\n",
    "from src.funcs.decorators import timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27eaa189",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/vasu/Library/CloudStorage/OneDrive-DecisionTreeAnalyticsServices/TensorDynamics/Data/Satellite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f1b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = create_db_connection(dbname=db_config.dbname,\n",
    "                                     host=db_config.host,\n",
    "                                     port=db_config.port,\n",
    "                                     user=db_config.user,\n",
    "                                     password=db_config.password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb553bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df = read_table_to_df(con=db_connection,\n",
    "                                table_str=db_config.site_table,\n",
    "                                schema=db_config.site_table_schema)\n",
    "\n",
    "locations_dict = process_site_table(site_df=locations_df, site_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116861a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file_paths = get_all_file_paths_in_dir(folder_path=data_path,\n",
    "                                          find_match='S_NWC_CT',\n",
    "                                          ignore_matches=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46f4725",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nc_file_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sample_file \u001b[38;5;241m=\u001b[39m \u001b[43mnc_file_paths\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nc_file_paths' is not defined"
     ]
    }
   ],
   "source": [
    "sample_file = nc_file_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3eb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class to extract data from a NETCDF file\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import haversine\n",
    "\n",
    "\n",
    "class SatelliteNCExtractor:\n",
    "\n",
    "    def __init__(self,\n",
    "                 nc_file_path,\n",
    "                 locations_dict=None,\n",
    "                 lat_col=None,\n",
    "                 lon_col=None,\n",
    "                 exclude_cols_str_matching=None,\n",
    "                 extract_attrs=None):\n",
    "        \"\"\"\n",
    "        Extracts dataframe from NETCDF File with given params\n",
    "\n",
    "        :param nc_file_path: File path to read\n",
    "        :type nc_file_path: str, path like\n",
    "\n",
    "        :param locations_dict: locations dictionary to filter netcdf file variables. Optional, default to None.\n",
    "            Will return all lat lon info if None.\n",
    "        :type locations_dict: dict\n",
    "\n",
    "        :param lat_col: Latitude index label in netcdf file. Optional, defaults to None - will try to infer\n",
    "        :type lat_col: str\n",
    "\n",
    "        :param lon_col: Longitude index label in netcdf file. Optional, defaults to None - will try to infer\n",
    "        :type lon_col: str\n",
    "\n",
    "        :param time_col: Time column index in netcdf file. Optional, defaults to None - will try to infer\n",
    "        :type time_col: str\n",
    "\n",
    "        :param exclude_cols_str_matching: List of string matches to avoid in output. Can be part of the column names.\n",
    "            Optional, defaults to ['bnds']. i.e. all column labels with 'bnds' will be omitted.\n",
    "        :type exclude_cols_str_matching: [str], list of str\n",
    "\n",
    "        :param extract_attrs: List of attribute names of the netcdf file to extract.\n",
    "            Defaults to ['title', 'experiment', 'creation_date']\n",
    "        :type lat_col: [str], list of str\n",
    "        \"\"\"\n",
    "        self.file_path = nc_file_path\n",
    "        self.locs_dict = locations_dict\n",
    "        self.lat_col = lat_col\n",
    "        self.lon_col = lon_col\n",
    "        self.exclude_cols_str_matching = exclude_cols_str_matching or ['bnds']\n",
    "        self.global_attrs = extract_attrs or ['keywords', \n",
    "                                              'date_created',\n",
    "                                              'time_coverage_start', \n",
    "                                              'time_coverage_end',\n",
    "                                              'product_name',\n",
    "                                              'nominal_product_time',\n",
    "                                              'satellite_identifier', \n",
    "                                              'id', \n",
    "                                              'summary', \n",
    "                                              'title']\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_haversine_dist(loc1, loc2, unit='KM') -> float:\n",
    "        \"\"\"\n",
    "        Calculates haversine (great-circle) distance between two co-ordinates in km\n",
    "        :param loc1: location 1 (lat1, lon1)\n",
    "        :param loc2: location 2 (lat2, lon2)\n",
    "        :param unit: UNITS of distance, optional, defaults to KM. Options = [KM, MI] i.e. [kilometers, miles]\n",
    "        :return: distance in unit\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        if not isinstance(loc1, tuple) or not isinstance(loc2, tuple):\n",
    "            raise TypeError(\"Cannot calculate distance. Please provide location as (lat, lon) \")\n",
    "\n",
    "        if 'km' in unit.lower():\n",
    "            unit = haversine.Unit.KILOMETERS\n",
    "        elif 'mi' in unit.lower():\n",
    "            unit = haversine.Unit.MILES\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only 'km' or 'mi' are implemented units while calculating haversine distance.\")\n",
    "        return haversine.haversine(point1=loc1, point2=loc2, unit=unit)\n",
    "    \n",
    "    @staticmethod\n",
    "    def haversine_np(lon1, lat1, lon2, lat2):\n",
    "        \"\"\"\n",
    "        Calculate the great circle distance between two points\n",
    "        on the earth (specified in decimal degrees)\n",
    "\n",
    "        All args must be of equal length.    \n",
    "\n",
    "        \"\"\"\n",
    "        lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "\n",
    "        a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        km = 6367 * c\n",
    "        return km\n",
    "    \n",
    "    @staticmethod\n",
    "    def drop_columns_matching(data_frame, col_matches) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Drops columns from the dataframe that matches any given str in the iter of col_matches\n",
    "        \"\"\"\n",
    "        temp_df = data_frame.copy()\n",
    "        drop_cols = [col for col in data_frame.columns if any(x.lower() in col.lower() for x in col_matches)]\n",
    "        return temp_df.drop(drop_cols, axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_attrs_from_xarray(xarray_obj, attr_names) -> dict:\n",
    "        \"\"\"Extract attributes from NC file with the given attr_names\"\"\"\n",
    "        return {name: xarray_obj.attrs.get(name) for name in attr_names}\n",
    "\n",
    "    @staticmethod\n",
    "    def add_dict_items_to_df(data_frame, attr_dict, prefix=None):\n",
    "        temp_df = data_frame.copy()\n",
    "        counter = 0\n",
    "        for attr, value in attr_dict.items():\n",
    "            name = f\"{prefix}_{attr}\" if prefix else attr\n",
    "            temp_df.insert(loc=counter, column=name, value=value)\n",
    "            counter += 1\n",
    "        return temp_df\n",
    "\n",
    "    @staticmethod\n",
    "    def get_timezone(xarray_obj):\n",
    "        return str(pd.to_datetime(xarray_obj.attrs.get('date_created', None)).tz)\n",
    "    \n",
    "    @staticmethod\n",
    "    def replace_special_chars(my_string, replace_with='_') -> str:\n",
    "        \"\"\"\n",
    "        Replaces special characs from a string with regex.\n",
    "        \"\"\"\n",
    "        return re.sub('[^A-Za-z0-9]+', replace_with, my_string).lower()\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_all_vars(xr_obj):\n",
    "        output_df = pd.DataFrame()\n",
    "        var_names = list(xr_obj.variables.keys())\n",
    "        for var in var_names:\n",
    "            var_obj = xr_obj.variables.get(var)\n",
    "            if var_obj is not None:\n",
    "                melted_var = pd.DataFrame({var: var_obj.values.ravel()})\n",
    "                output_df = pd.concat([output_df, melted_var], axis=1)\n",
    "        return output_df\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_time_index_to_datetime(data_frame, time_col):\n",
    "        temp_df = data_frame.copy()\n",
    "        temp_df[time_col] = pd.to_datetime(temp_df[time_col])\n",
    "        # temp_df[time_col] = temp_df[time_col].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        # temp_df[time_col] = pd.to_datetime(temp_df[time_col], format='%Y-%m-%d %H:%M:%S')\n",
    "        return temp_df\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_cords(xr_obj, lat_col, lon_col):\n",
    "        melted_lats = pd.DataFrame({lat_col: xr_obj.coords[lat_col].values.ravel()})\n",
    "        melted_lons = pd.DataFrame({lon_col: xr_obj.coords[lon_col].values.ravel()})\n",
    "        return pd.concat([melted_lats, melted_lons], axis=1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_k_closest_number(find_number, search_array, k):\n",
    "        return nsmallest(k, search_array, key=lambda x: abs(x - find_number))\n",
    "    \n",
    "    def open_xarray_obj(self):\n",
    "        \"\"\"Opens xarray dataframe from netcdf file\"\"\"\n",
    "        return xr.open_dataset(self.file_path)\n",
    "\n",
    "    def add_timezone(self, data_frame, xarray_obj):\n",
    "        temp_df = data_frame.copy()\n",
    "        temp_df['tz'] = self.get_timezone(xarray_obj=xarray_obj)\n",
    "        return temp_df\n",
    "    \n",
    "    def clean_col_names(self, data_frame) -> pd.DataFrame:\n",
    "        \"\"\"Clean column names from special characters\"\"\"\n",
    "        temp_df = data_frame.copy()\n",
    "        temp_df.columns = [self.replace_special_chars(col) for col in temp_df.columns]\n",
    "        return temp_df\n",
    "\n",
    "    def find_closest_distance_haversine_np(self, locations_dict, lat_lon_df, lat_col='lat', lon_col='lon'):\n",
    "        output_dict = {}\n",
    "        for location in locations_dict:\n",
    "            site_actual_location = locations_dict.get(location)\n",
    "            site_lat = site_actual_location[0]\n",
    "            site_lon = site_actual_location[1]\n",
    "\n",
    "            temp_df = lat_lon_df.copy()\n",
    "            temp_df['site_lat'] = site_lat\n",
    "            temp_df['site_lon'] = site_lon\n",
    "            temp_df['distance'] = self.haversine_np(lon1=temp_df[lon_col],\n",
    "                                                    lat1=temp_df[lat_col],\n",
    "                                                    lon2=temp_df['site_lon'],\n",
    "                                                    lat2=temp_df['site_lat'])\n",
    "            required_row = temp_df.loc[temp_df['distance'].idxmin()]\n",
    "            required_lat = required_row.loc[lat_col]\n",
    "            required_lon = required_row.loc[lon_col]\n",
    "            required_distance = required_row.loc['distance']\n",
    "            output_row = {location: {'NC': (required_lat, required_lon), 'SITE': site_actual_location}}\n",
    "            output_dict.update(output_row)\n",
    "        return output_dict\n",
    "\n",
    "    def get_closest_nc_distances(self, locations_dict, xarray_df, lat_col, lon_col) -> dict:\n",
    "        \"\"\"\n",
    "        Prepares a dictionary of actual site lat lons and the closes lat lons in a dataframe\n",
    "        :param locations_dict: Locations dict in format {site : (lat, lon), site2: (lat2, lon2). .. .}\n",
    "        :param xarray_df: dataframe containing lat lon cols to search from\n",
    "        :param lat_col: column label containing lats\n",
    "        :param lon_col: column label containing lons\n",
    "        :return: dictionary of actual site lat lons and the closes lat lons found\n",
    "            {'site: {'SITE': (lat, lon), 'NC':(lat`, lon`)}, 'site2':{'SITE': (lat, lon), 'NC':(lat`, lon`)} ... }\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        lat_lon_df = xarray_df[[lat_col, lon_col]].drop_duplicates().reset_index(drop=True).copy()\n",
    "        output_dict = self.find_closest_distance_haversine_np(locations_dict=locations_dict, \n",
    "                                                              lat_lon_df=lat_lon_df,\n",
    "                                                              lat_col=lat_col,\n",
    "                                                              lon_col=lon_col)\n",
    "        return output_dict\n",
    "\n",
    "    def filter_xarray_df_for_locs(self, xarray_df, location_dict, lat_col, lon_col) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filter xarray dataframe for incoming locations\n",
    "        :param xarray_df: xarray df\n",
    "        :param location_dict: Locations dict in format {site : (lat, lon), site2: (lat2, lon2). .. .}\n",
    "        :param lat_col: col label containing latitude\n",
    "        :param lon_col: col label containing longitude\n",
    "        :return: netcdf dataframe filtered for locations\n",
    "        \"\"\"\n",
    "        # GET AVAIL LOCATIONS\n",
    "        locations_dict_nc = self.get_closest_nc_distances(locations_dict=location_dict,\n",
    "                                                          xarray_df=xarray_df,\n",
    "                                                          lat_col=lat_col,\n",
    "                                                          lon_col=lon_col)\n",
    "        # ITER OVER SITES\n",
    "        file_df = pd.DataFrame()\n",
    "        for location_name, location_meta in locations_dict_nc.items():\n",
    "            actual_site_loc = location_meta['SITE']\n",
    "            nc_site_loc = location_meta['NC']\n",
    "\n",
    "            loc_df = xarray_df[(xarray_df[lat_col] == nc_site_loc[0]) &\n",
    "                               (xarray_df[lon_col] == nc_site_loc[1])].copy().reset_index(drop=True)\n",
    "            loc_df['site_name'] = location_name\n",
    "            loc_df['site_lat'] = actual_site_loc[0]\n",
    "            loc_df['site_lon'] = actual_site_loc[0]\n",
    "            loc_df['distance_site_grid_point_km'] = self.calc_haversine_dist(loc1=actual_site_loc,\n",
    "                                                                             loc2=nc_site_loc,\n",
    "                                                                             unit='KM')\n",
    "            file_df = pd.concat([file_df, loc_df], axis=0)\n",
    "        return file_df.reset_index(drop=True)\n",
    "\n",
    "    def get_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        wrapper for:\n",
    "        1. Conversion process from NETCDF TO XARRAY\n",
    "        2. Extracting attributes & dataframe\n",
    "        3. Filtering for locations\n",
    "        4. Cleaning of column names and dropping extra columns\n",
    "        \"\"\"\n",
    "        xarray_obj = self.open_xarray_obj()  # OPEN X ARRAY OBJECT\n",
    "        xarray_attrs = self.get_attrs_from_xarray(xarray_obj=xarray_obj,\n",
    "                                                  attr_names=self.global_attrs)  # EXTRACT ATTRIBUTES\n",
    "        \n",
    "        xarray_df = self.extract_all_vars(xr_obj=xarray_obj)\n",
    "        if self.locs_dict:\n",
    "            xarray_df = self.filter_xarray_df_for_locs(xarray_df=xarray_df,\n",
    "                                                       location_dict=self.locs_dict,\n",
    "                                                       lat_col=self.lat_col,\n",
    "                                                       lon_col=self.lon_col)\n",
    "\n",
    "        xarray_df = (xarray_df\n",
    "                     .pipe(self.drop_columns_matching, self.exclude_cols_str_matching)  # EXCLUDE COLS (Optional)\n",
    "                     .pipe(self.add_timezone, xarray_obj)  # ADD TIME ZONE IF PRESENT  (FROM 'date_created' attr)\n",
    "                     .pipe(self.add_dict_items_to_df, xarray_attrs)  # ADD ATTRIBUTES FROM NETCDF ATTRIBUTES\n",
    "                     .pipe(self.convert_time_index_to_datetime, 'nominal_product_time')  # CONVERT COL TO DATETIME LIKE\n",
    "                     .pipe(self.convert_time_index_to_datetime, 'date_created')  # CONVERT COL TO DATETIME LIKE\n",
    "                     .pipe(self.convert_time_index_to_datetime, 'time_coverage_start')  # CONVERT COL TO DATETIME LIKE\n",
    "                     .pipe(self.convert_time_index_to_datetime, 'time_coverage_end')  # CONVERT COL TO DATETIME LIKE\n",
    "                     .pipe(self.clean_col_names)  # REMOVE SPECIAL CHARS FROM COL NAMES\n",
    "                     )\n",
    "        return xarray_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32285e79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████████████████████▎                                                                                                                                      | 104/566 [02:28<11:00,  1.43s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(nc_file_paths):\n",
    "    time_stamp_data = SatelliteNCExtractor(nc_file_path=file, \n",
    "                                           locations_dict=locations_dict, \n",
    "                                           lat_col='lat',\n",
    "                                           lon_col='lon', \n",
    "                                           exclude_cols_str_matching=['nx', 'ny']).get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ca9e0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_flag_names = pd.DataFrame()\n",
    "# for variable in ['ct', 'ct_cumuliform', 'ct_multilayer', \n",
    "#                  #'ct_status_flag',\n",
    "#                  #'ct_conditions',\n",
    "#                  #'ct_quality'\n",
    "#                 ]:\n",
    "#     ct_variable = xr_obj.variables[variable]\n",
    "#     variable_long_name = ct_variable.attrs.get('long_name')\n",
    "#     variable_range = ct_variable.attrs.get('valid_range')\n",
    "#     variable_range = f\"{min(variable_range)} - {max(variable_range)}\"\n",
    "#     flag_values = ct_variable.attrs.get('flag_values')\n",
    "#     flag_meanings = ct_variable.attrs.get('flag_meanings').split(' ')\n",
    "    \n",
    "#     # VARIABLE META DF\n",
    "#     variable_meta_df = pd.DataFrame({'flag_value': flag_values, \n",
    "#                                      'flag_meaning': flag_meanings,})\n",
    "#     variable_meta_df.insert(loc=0, column='valid_range', value=variable_range)\n",
    "#     variable_meta_df.insert(loc=0, column='variable_long_name', value=variable_long_name)\n",
    "#     variable_meta_df.insert(loc=0, column='variable', value=variable)\n",
    "    \n",
    "#     master_flag_names = pd.concat([master_flag_names, variable_meta_df], axis=0)\n",
    "# master_flag_names.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a7648fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append_data_to_table(data=master_flag_names,\n",
    "#                      db_url=tensor_aws_db1_url(),\n",
    "#                      table_name='ct_meta_info',\n",
    "#                      schema='td_satellite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d941a0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7a4a397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3bf2b41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46906a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e76209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2757cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dcce60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4efac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
